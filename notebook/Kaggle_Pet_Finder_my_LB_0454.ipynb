{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import cv2\n",
    "from keras.applications.densenet import preprocess_input, DenseNet121\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import scipy as sp\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "split_char = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adoption-prediction\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adoption-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+\"train.csv\")\n",
    "test = pd.read_csv(path+\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract Image Feature\n",
    "from https://www.kaggle.com/christofhenkel/extract-image-features-from-pretrained-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2]\n",
    "    ratio = float(img_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    delta_w = img_size - new_size[1]\n",
    "    delta_h = img_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_im\n",
    "\n",
    "def load_image(path, pet_id):\n",
    "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
    "    new_image = resize_to_square(image)\n",
    "    new_image = preprocess_input(new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((256,256,3))\n",
    "backbone = DenseNet121(input_tensor = inp, \n",
    "                       weights=path + \"densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n",
    "                       include_top = False)\n",
    "x = backbone.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\n",
    "x = AveragePooling1D(4)(x)\n",
    "out = Lambda(lambda x: x[:,:,0])(x)\n",
    "\n",
    "m = Model(inp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [1:22:55<00:00, 73.13s/it]\n"
     ]
    }
   ],
   "source": [
    "pet_ids = train['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(path+\"train_images/\", pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "train_feats.columns = [f'pic_{i}' for i in range(train_feats.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [21:22<00:00, 68.81s/it]\n"
     ]
    }
   ],
   "source": [
    "pet_ids = test['PetID'].values\n",
    "n_batches = len(pet_ids) // batch_size + 1\n",
    "\n",
    "features = {}\n",
    "for b in tqdm(range(n_batches)):\n",
    "    start = b*batch_size\n",
    "    end = (b+1)*batch_size\n",
    "    batch_pets = pet_ids[start:end]\n",
    "    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        try:\n",
    "            batch_images[i] = load_image(path+\"test_images/\", pet_id)\n",
    "        except:\n",
    "            pass\n",
    "    batch_preds = m.predict(batch_images)\n",
    "    for i,pet_id in enumerate(batch_pets):\n",
    "        features[pet_id] = batch_preds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = pd.DataFrame.from_dict(features, orient='index')\n",
    "test_feats.columns = [f'pic_{i}' for i in range(test_feats.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = train_feats.reset_index()\n",
    "train_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)\n",
    "\n",
    "test_feats = test_feats.reset_index()\n",
    "test_feats.rename({'index': 'PetID'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18941, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = pd.concat([train, test], axis=0, ignore_index=True, sort=False)[['PetID']]\n",
    "all_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 32\n",
    "svd_ = TruncatedSVD(n_components=n_components, random_state=1337)\n",
    "\n",
    "features_df = pd.concat([train_feats, test_feats], axis=0)\n",
    "features = features_df[[f'pic_{i}' for i in range(256)]].values\n",
    "\n",
    "svd_col = svd_.fit_transform(features)\n",
    "svd_col = pd.DataFrame(svd_col)\n",
    "svd_col = svd_col.add_prefix('IMG_SVD_')\n",
    "\n",
    "img_features = pd.concat([all_ids, svd_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Meta data and Sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_breed = pd.read_csv(path+'breed_labels.csv')\n",
    "labels_state = pd.read_csv(path+'color_labels.csv')\n",
    "labels_color = pd.read_csv(path+'state_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train images files: 58311\n",
      "num of train metadata files: 58311\n",
      "num of train sentiment files: 14442\n",
      "num of test images files: 15040\n",
      "num of test metadata files: 15040\n",
      "num of test sentiment files: 3815\n"
     ]
    }
   ],
   "source": [
    "train_image_files = sorted(glob.glob(path+'train_images/*.jpg'))\n",
    "train_metadata_files = sorted(glob.glob(path+'train_metadata/*.json'))\n",
    "train_sentiment_files = sorted(glob.glob(path+'train_sentiment/*.json'))\n",
    "\n",
    "print(f'num of train images files: {len(train_image_files)}')\n",
    "print(f'num of train metadata files: {len(train_metadata_files)}')\n",
    "print(f'num of train sentiment files: {len(train_sentiment_files)}')\n",
    "\n",
    "\n",
    "test_image_files = sorted(glob.glob(path+'test_images/*.jpg'))\n",
    "test_metadata_files = sorted(glob.glob(path+'test_metadata/*.json'))\n",
    "test_sentiment_files = sorted(glob.glob(path+'test_sentiment/*.json'))\n",
    "\n",
    "print(f'num of test images files: {len(test_image_files)}')\n",
    "print(f'num of test metadata files: {len(test_metadata_files)}')\n",
    "print(f'num of test sentiment files: {len(test_sentiment_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Process Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 1)\n",
      "14652\n",
      "fraction of pets with metadata: 0.977\n",
      "14442\n",
      "fraction of pets with sentiment: 0.963\n"
     ]
    }
   ],
   "source": [
    "# Images:\n",
    "train_df_ids = train[['PetID']]\n",
    "print(train_df_ids.shape)\n",
    "\n",
    "# Metadata:\n",
    "train_df_ids = train[['PetID']]\n",
    "train_df_metadata = pd.DataFrame(train_metadata_files)\n",
    "train_df_metadata.columns = ['metadata_filename']\n",
    "train_metadata_pets = train_df_metadata['metadata_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "train_df_metadata = train_df_metadata.assign(PetID=train_metadata_pets)\n",
    "print(len(train_metadata_pets.unique()))\n",
    "\n",
    "pets_with_metadatas = len(np.intersect1d(train_metadata_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with metadata: {pets_with_metadatas / train_df_ids.shape[0]:.3f}')\n",
    "\n",
    "# Sentiment:\n",
    "train_df_ids = train[['PetID']]\n",
    "train_df_sentiment = pd.DataFrame(train_sentiment_files)\n",
    "train_df_sentiment.columns = ['sentiment_filename']\n",
    "train_sentiment_pets = train_df_sentiment['sentiment_filename'].apply(lambda x: x.split(split_char)[-1].split('.')[0])\n",
    "train_df_sentiment = train_df_sentiment.assign(PetID=train_sentiment_pets)\n",
    "print(len(train_sentiment_pets.unique()))\n",
    "\n",
    "pets_with_sentiments = len(np.intersect1d(train_sentiment_pets.unique(), train_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with sentiment: {pets_with_sentiments / train_df_ids.shape[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Process Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3948, 1)\n",
      "3821\n",
      "fraction of pets with metadata: 0.968\n",
      "3815\n",
      "fraction of pets with sentiment: 0.966\n"
     ]
    }
   ],
   "source": [
    "# Images:\n",
    "test_df_ids = test[['PetID']]\n",
    "print(test_df_ids.shape)\n",
    "\n",
    "# Metadata:\n",
    "test_df_metadata = pd.DataFrame(test_metadata_files)\n",
    "test_df_metadata.columns = ['metadata_filename']\n",
    "test_metadata_pets = test_df_metadata['metadata_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "test_df_metadata = test_df_metadata.assign(PetID=test_metadata_pets)\n",
    "print(len(test_metadata_pets.unique()))\n",
    "\n",
    "pets_with_metadatas = len(np.intersect1d(test_metadata_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with metadata: {pets_with_metadatas / test_df_ids.shape[0]:.3f}')\n",
    "\n",
    "# Sentiment:\n",
    "test_df_sentiment = pd.DataFrame(test_sentiment_files)\n",
    "test_df_sentiment.columns = ['sentiment_filename']\n",
    "test_sentiment_pets = test_df_sentiment['sentiment_filename'].apply(lambda x: x.split(split_char)[-1].split('.')[0])\n",
    "test_df_sentiment = test_df_sentiment.assign(PetID=test_sentiment_pets)\n",
    "print(len(test_sentiment_pets.unique()))\n",
    "\n",
    "pets_with_sentiments = len(np.intersect1d(test_sentiment_pets.unique(), test_df_ids['PetID'].unique()))\n",
    "print(f'fraction of pets with sentiment: {pets_with_sentiments / test_df_ids.shape[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_filename</th>\n",
       "      <th>PetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...</td>\n",
       "      <td>0008c5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...</td>\n",
       "      <td>000a290e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...</td>\n",
       "      <td>000fb9572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...</td>\n",
       "      <td>0011d7c25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...</td>\n",
       "      <td>00156db4a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sentiment_filename      PetID\n",
       "0  /Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...  0008c5398\n",
       "1  /Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...  000a290e4\n",
       "2  /Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...  000fb9572\n",
       "3  /Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...  0011d7c25\n",
       "4  /Volumes/Shikui Wang/Kaggle/Pet/petfinder-adop...  00156db4a"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract features from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderParser(object):\n",
    "    \n",
    "    def __init__(self, debug=False):\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.sentence_sep = ' '\n",
    "        \n",
    "        self.extract_sentiment_text = False\n",
    "    \n",
    "    def open_json_file(self, filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            json_file = json.load(f)\n",
    "        return json_file\n",
    "        \n",
    "    def parse_sentiment_file(self, file):\n",
    "        \"\"\"\n",
    "        Parse sentiment file. Output DF with sentiment features.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_sentiment = file['documentSentiment']\n",
    "        file_entities = [x['name'] for x in file['entities']]\n",
    "        file_entities = self.sentence_sep.join(file_entities)\n",
    "        \n",
    "        file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n",
    "        \n",
    "        file_sentences_sentiment = pd.DataFrame.from_dict(\n",
    "            file_sentences_sentiment, orient='columns')\n",
    "        file_sentences_sentiment_df = pd.DataFrame(\n",
    "            {\n",
    "                'magnitude_sum': file_sentences_sentiment['magnitude'].sum(axis=0),\n",
    "                'score_sum': file_sentences_sentiment['score'].sum(axis=0),\n",
    "                'magnitude_mean': file_sentences_sentiment['magnitude'].mean(axis=0),\n",
    "                'score_mean': file_sentences_sentiment['score'].mean(axis=0),\n",
    "                'magnitude_var': file_sentences_sentiment['magnitude'].var(axis=0),\n",
    "                'score_var': file_sentences_sentiment['score'].var(axis=0),\n",
    "            }, index=[0]\n",
    "        )\n",
    "        \n",
    "        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n",
    "        df_sentiment = pd.concat([df_sentiment, file_sentences_sentiment_df], axis=1)\n",
    "            \n",
    "        df_sentiment['entities'] = file_entities\n",
    "        df_sentiment = df_sentiment.add_prefix('sentiment_')\n",
    "        \n",
    "        return df_sentiment\n",
    "    \n",
    "    def parse_metadata_file(self, file):\n",
    "        \"\"\"\n",
    "        Parse metadata file. Output DF with metadata features.\n",
    "        \"\"\"\n",
    "        \n",
    "        file_keys = list(file.keys())\n",
    "        \n",
    "        if 'labelAnnotations' in file_keys:\n",
    "            file_annots = file['labelAnnotations']\n",
    "            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n",
    "            file_top_desc = [x['description'] for x in file_annots]\n",
    "        else:\n",
    "            file_top_score = np.nan\n",
    "            file_top_desc = ['']\n",
    "        \n",
    "        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        file_crops = file['cropHintsAnnotation']['cropHints']\n",
    "\n",
    "        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n",
    "        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n",
    "\n",
    "        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n",
    "        \n",
    "        if 'importanceFraction' in file_crops[0].keys():\n",
    "            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n",
    "        else:\n",
    "            file_crop_importance = np.nan\n",
    "\n",
    "        df_metadata = {\n",
    "            'annots_score': file_top_score,\n",
    "            'color_score': file_color_score,\n",
    "            'color_pixelfrac': file_color_pixelfrac,\n",
    "            'crop_conf': file_crop_conf,\n",
    "            'crop_importance': file_crop_importance,\n",
    "            'annots_top_desc': self.sentence_sep.join(file_top_desc)\n",
    "        }\n",
    "        \n",
    "        df_metadata = pd.DataFrame.from_dict(df_metadata, orient='index').T\n",
    "        df_metadata = df_metadata.add_prefix('metadata_')\n",
    "        \n",
    "        return df_metadata\n",
    "    \n",
    "\n",
    "def extract_additional_features(pet_id, mode='train'):\n",
    "    \n",
    "    sentiment_filename = f'/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adoption-prediction/{mode}_sentiment/{pet_id}.json'\n",
    "    try:\n",
    "        sentiment_file = pet_parser.open_json_file(sentiment_filename)\n",
    "        df_sentiment = pet_parser.parse_sentiment_file(sentiment_file)\n",
    "        df_sentiment['PetID'] = pet_id\n",
    "    except FileNotFoundError:\n",
    "        df_sentiment = []\n",
    "\n",
    "    dfs_metadata = []\n",
    "    metadata_filenames = sorted(glob.glob(f'/Volumes/Shikui Wang/Kaggle/Pet/petfinder-adoption-prediction/{mode}_metadata/{pet_id}*.json'))\n",
    "    if len(metadata_filenames) > 0:\n",
    "        for f in metadata_filenames:\n",
    "            metadata_file = pet_parser.open_json_file(f)\n",
    "            df_metadata = pet_parser.parse_metadata_file(metadata_file)\n",
    "            df_metadata['PetID'] = pet_id\n",
    "            dfs_metadata.append(df_metadata)\n",
    "        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n",
    "    dfs = [df_sentiment, dfs_metadata]\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "\n",
    "pet_parser = PetFinderParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pet_ids = train.PetID.unique()\n",
    "test_pet_ids = test.PetID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 21.7min\n",
      "[Parallel(n_jobs=-1)]: Done 14993 out of 14993 | elapsed: 22.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14442, 10) (58311, 7)\n"
     ]
    }
   ],
   "source": [
    "dfs_train = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(extract_additional_features)(i, mode='train') for i in train_pet_ids)\n",
    "\n",
    "train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\n",
    "train_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "train_dfs_sentiment = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\n",
    "train_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "print(train_dfs_sentiment.shape, train_dfs_metadata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 769 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1384 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1960 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2980 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3948 out of 3948 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3815, 10) (15040, 7)\n"
     ]
    }
   ],
   "source": [
    "dfs_test = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)\n",
    "\n",
    "test_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\n",
    "test_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]\n",
    "\n",
    "test_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\n",
    "test_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)\n",
    "\n",
    "print(test_dfs_sentiment.shape, test_dfs_metadata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = ['sum', 'mean', 'var']\n",
    "sent_agg = ['sum']\n",
    "\n",
    "\n",
    "# Train\n",
    "train_metadata_desc = train_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "train_metadata_desc = train_metadata_desc.reset_index()\n",
    "train_metadata_desc[\n",
    "    'metadata_annots_top_desc'] = train_metadata_desc[\n",
    "    'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "train_metadata_gr = train_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in train_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_metadata_gr[i] = train_metadata_gr[i].astype(float)\n",
    "train_metadata_gr = train_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "train_metadata_gr.columns = pd.Index([f'{c[0]}_{c[1].upper()}' for c in train_metadata_gr.columns.tolist()])\n",
    "train_metadata_gr = train_metadata_gr.reset_index()\n",
    "\n",
    "\n",
    "train_sentiment_desc = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "train_sentiment_desc = train_sentiment_desc.reset_index()\n",
    "train_sentiment_desc[\n",
    "    'sentiment_entities'] = train_sentiment_desc[\n",
    "    'sentiment_entities'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "train_sentiment_gr = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in train_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        train_sentiment_gr[i] = train_sentiment_gr[i].astype(float)\n",
    "train_sentiment_gr = train_sentiment_gr.groupby(['PetID']).agg(sent_agg)\n",
    "train_sentiment_gr.columns = pd.Index([f'{c[0]}' for c in train_sentiment_gr.columns.tolist()])\n",
    "train_sentiment_gr = train_sentiment_gr.reset_index()\n",
    "\n",
    "\n",
    "# Test\n",
    "test_metadata_desc = test_dfs_metadata.groupby(['PetID'])['metadata_annots_top_desc'].unique()\n",
    "test_metadata_desc = test_metadata_desc.reset_index()\n",
    "test_metadata_desc[\n",
    "    'metadata_annots_top_desc'] = test_metadata_desc[\n",
    "    'metadata_annots_top_desc'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'metadata'\n",
    "test_metadata_gr = test_dfs_metadata.drop(['metadata_annots_top_desc'], axis=1)\n",
    "for i in test_metadata_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_metadata_gr[i] = test_metadata_gr[i].astype(float)\n",
    "        ######## AGGREGATE HERE\n",
    "test_metadata_gr = test_metadata_gr.groupby(['PetID']).agg(aggregates)\n",
    "test_metadata_gr.columns = pd.Index([f'{c[0]}_{c[1].upper()}' for c in test_metadata_gr.columns.tolist()])\n",
    "test_metadata_gr = test_metadata_gr.reset_index()\n",
    "\n",
    "\n",
    "test_sentiment_desc = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\n",
    "test_sentiment_desc = test_sentiment_desc.reset_index()\n",
    "test_sentiment_desc[\n",
    "    'sentiment_entities'] = test_sentiment_desc[\n",
    "    'sentiment_entities'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "prefix = 'sentiment'\n",
    "test_sentiment_gr = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n",
    "for i in test_sentiment_gr.columns:\n",
    "    if 'PetID' not in i:\n",
    "        test_sentiment_gr[i] = test_sentiment_gr[i].astype(float)\n",
    "        ###### AGGREGATE HERE\n",
    "test_sentiment_gr = test_sentiment_gr.groupby(['PetID']).agg(sent_agg)\n",
    "test_sentiment_gr.columns = pd.Index([f'{c[0]}' for c in test_sentiment_gr.columns.tolist()])\n",
    "test_sentiment_gr = test_sentiment_gr.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 49) (3948, 48)\n"
     ]
    }
   ],
   "source": [
    "# Train merges:\n",
    "train_proc = train.copy()\n",
    "train_proc = train_proc.merge(\n",
    "    train_sentiment_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_metadata_gr, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_metadata_desc, how='left', on='PetID')\n",
    "train_proc = train_proc.merge(\n",
    "    train_sentiment_desc, how='left', on='PetID')\n",
    "\n",
    "# Test merges:\n",
    "test_proc = test.copy()\n",
    "test_proc = test_proc.merge(\n",
    "    test_sentiment_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_metadata_gr, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_metadata_desc, how='left', on='PetID')\n",
    "test_proc = test_proc.merge(\n",
    "    test_sentiment_desc, how='left', on='PetID')\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join breed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 53) (3948, 52)\n"
     ]
    }
   ],
   "source": [
    "train_breed_main = train_proc[['Breed1']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed1', right_on='BreedID',\n",
    "    suffixes=('', '_main_breed'))\n",
    "\n",
    "train_breed_main = train_breed_main.iloc[:, 2:]\n",
    "train_breed_main = train_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "train_breed_second = train_proc[['Breed2']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed2', right_on='BreedID',\n",
    "    suffixes=('', '_second_breed'))\n",
    "\n",
    "train_breed_second = train_breed_second.iloc[:, 2:]\n",
    "train_breed_second = train_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "\n",
    "train_proc = pd.concat(\n",
    "    [train_proc, train_breed_main, train_breed_second], axis=1)\n",
    "\n",
    "\n",
    "test_breed_main = test_proc[['Breed1']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed1', right_on='BreedID',\n",
    "    suffixes=('', '_main_breed'))\n",
    "\n",
    "test_breed_main = test_breed_main.iloc[:, 2:]\n",
    "test_breed_main = test_breed_main.add_prefix('main_breed_')\n",
    "\n",
    "test_breed_second = test_proc[['Breed2']].merge(\n",
    "    labels_breed, how='left',\n",
    "    left_on='Breed2', right_on='BreedID',\n",
    "    suffixes=('', '_second_breed'))\n",
    "\n",
    "test_breed_second = test_breed_second.iloc[:, 2:]\n",
    "test_breed_second = test_breed_second.add_prefix('second_breed_')\n",
    "\n",
    "\n",
    "test_proc = pd.concat(\n",
    "    [test_proc, test_breed_main, test_breed_second], axis=1)\n",
    "\n",
    "print(train_proc.shape, test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X.copy()\n",
    "\n",
    "text_columns = ['Description', 'metadata_annots_top_desc', 'sentiment_entities']\n",
    "categorical_columns = ['main_breed_BreedName', 'second_breed_BreedName']\n",
    "\n",
    "to_drop_columns = ['PetID', 'Name', 'RescuerID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescuer ID\n",
    "rescuer_count = X.groupby(['RescuerID'])['PetID'].count().reset_index()\n",
    "rescuer_count.columns = ['RescuerID', 'RescuerID_COUNT']\n",
    "\n",
    "X_temp = X_temp.merge(rescuer_count, how='left', on='RescuerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Category\n",
    "for i in categorical_columns:\n",
    "    X_temp.loc[:, i] = pd.factorize(X_temp.loc[:, i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = X_temp[text_columns]\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_text.loc[:, i] = X_text.loc[:, i].fillna('none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp['Length_Description'] = X_text['Description'].map(len)\n",
    "X_temp['Length_metadata_annots_top_desc'] = X_text['metadata_annots_top_desc'].map(len)\n",
    "X_temp['Lengths_sentiment_entities'] = X_text['sentiment_entities'].map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features from: Description\n",
      "generating features from: metadata_annots_top_desc\n",
      "generating features from: sentiment_entities\n"
     ]
    }
   ],
   "source": [
    "n_components = 16\n",
    "text_features = []\n",
    "\n",
    "# Generate text features:\n",
    "for i in X_text.columns:\n",
    "    \n",
    "    # Initialize decomposition methods:\n",
    "    print(f'generating features from: {i}')\n",
    "    tfv = TfidfVectorizer(min_df=2,  max_features=None,\n",
    "                          strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n",
    "                          ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "    svd_ = TruncatedSVD(\n",
    "        n_components=n_components, random_state=1337)\n",
    "    \n",
    "    tfidf_col = tfv.fit_transform(X_text.loc[:, i].values)\n",
    "    \n",
    "    svd_col = svd_.fit_transform(tfidf_col)\n",
    "    svd_col = pd.DataFrame(svd_col)\n",
    "    svd_col = svd_col.add_prefix('TFIDF_{}_'.format(i))\n",
    "    \n",
    "    text_features.append(svd_col)\n",
    "    \n",
    "text_features = pd.concat(text_features, axis=1)\n",
    "\n",
    "X_temp = pd.concat([X_temp, text_features], axis=1)\n",
    "\n",
    "for i in X_text.columns:\n",
    "    X_temp = X_temp.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X_temp.merge(img_features, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ids = train[['PetID']]\n",
    "test_df_ids = test[['PetID']]\n",
    "\n",
    "train_df_imgs = pd.DataFrame(train_image_files)\n",
    "train_df_imgs.columns = ['image_filename']\n",
    "train_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "\n",
    "test_df_imgs = pd.DataFrame(test_image_files)\n",
    "test_df_imgs.columns = ['image_filename']\n",
    "test_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split(split_char)[-1].split('-')[0])\n",
    "\n",
    "train_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\n",
    "test_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n",
    "\n",
    "def getSize(filename):\n",
    "    st = os.stat(filename)\n",
    "    return st.st_size\n",
    "\n",
    "def getDimensions(filename):\n",
    "    img_size = Image.open(filename).size\n",
    "    return img_size \n",
    "\n",
    "train_df_imgs['image_size'] = train_df_imgs['image_filename'].apply(getSize)\n",
    "train_df_imgs['temp_size'] = train_df_imgs['image_filename'].apply(getDimensions)\n",
    "train_df_imgs['width'] = train_df_imgs['temp_size'].apply(lambda x : x[0])\n",
    "train_df_imgs['height'] = train_df_imgs['temp_size'].apply(lambda x : x[1])\n",
    "train_df_imgs = train_df_imgs.drop(['temp_size'], axis=1)\n",
    "\n",
    "test_df_imgs['image_size'] = test_df_imgs['image_filename'].apply(getSize)\n",
    "test_df_imgs['temp_size'] = test_df_imgs['image_filename'].apply(getDimensions)\n",
    "test_df_imgs['width'] = test_df_imgs['temp_size'].apply(lambda x : x[0])\n",
    "test_df_imgs['height'] = test_df_imgs['temp_size'].apply(lambda x : x[1])\n",
    "test_df_imgs = test_df_imgs.drop(['temp_size'], axis=1)\n",
    "\n",
    "aggs = {\n",
    "    'image_size': ['sum', 'mean', 'var'],\n",
    "    'width': ['sum', 'mean', 'var'],\n",
    "    'height': ['sum', 'mean', 'var'],\n",
    "}\n",
    "\n",
    "agg_train_imgs = train_df_imgs.groupby('PetID').agg(aggs)\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "agg_train_imgs.columns = new_columns\n",
    "agg_train_imgs = agg_train_imgs.reset_index()\n",
    "\n",
    "agg_test_imgs = test_df_imgs.groupby('PetID').agg(aggs)\n",
    "new_columns = [\n",
    "    k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "]\n",
    "agg_test_imgs.columns = new_columns\n",
    "agg_test_imgs = agg_test_imgs.reset_index()\n",
    "\n",
    "agg_imgs = pd.concat([agg_train_imgs, agg_test_imgs], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X_temp.merge(agg_imgs, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X_temp.drop(to_drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_temp.loc[np.isfinite(X_temp.AdoptionSpeed), :]\n",
    "X_test = X_temp.loc[~np.isfinite(X_temp.AdoptionSpeed), :]\n",
    "\n",
    "X_test = X_test.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "assert X_train.shape[0] == train.shape[0]\n",
    "assert X_test.shape[0] == test.shape[0]\n",
    "\n",
    "train_cols = X_train.columns.tolist()\n",
    "train_cols.remove('AdoptionSpeed')\n",
    "\n",
    "test_cols = X_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_null = X_train.fillna(-1)\n",
    "X_test_non_null = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14993, 140), (3948, 139))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_non_null.shape, X_test_non_null.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OptimizeRounder\n",
    "from https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/76107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put numerical value to one of bins\n",
    "\n",
    "def to_bins(x, borders):\n",
    "    for i in range(len(borders)):\n",
    "        if x <= borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _loss(self, coef, X, y, idx):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        ll = -cohen_kappa_score(y, X_p, weights = \"quadratic\")\n",
    "        return ll\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        coef = [1.5, 2.0, 2.5, 3.0]\n",
    "        golden1 = 0.618\n",
    "        golden2 = 1 - golden1\n",
    "        ab_start = [(1, 2), (1.5, 2.5), (2, 3), (2.5, 3.5)]\n",
    "        for it1 in range(10):\n",
    "            for idx in range(4):\n",
    "                # golden section search\n",
    "                a, b = ab_start[idx]\n",
    "                # calc losses\n",
    "                coef[idx] = a\n",
    "                la = self._loss(coef, X, y, idx)\n",
    "                coef[idx] = b\n",
    "                lb = self._loss(coef, X, y, idx)\n",
    "                for it in range(20):\n",
    "                    # choose value\n",
    "                    if la > lb:\n",
    "                        a = b - (b - a) * golden1\n",
    "                        coef[idx] = a\n",
    "                        la = self._loss(coef, X, y, idx)\n",
    "                    else:\n",
    "                        b = b - (b - a) * golden2\n",
    "                        coef[idx] = b\n",
    "                        lb = self._loss(coef, X, y, idx)\n",
    "        self.coef_ = {'x': coef}\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        X_p = np.array([to_bins(pred, coef) for pred in X])\n",
    "        return X_p\n",
    "\n",
    "    def coefficients(self):\n",
    "        return self.coef_['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add External data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state population: https://en.wikipedia.org/wiki/Malaysia\n",
    "state_gdp = {\n",
    "    41336: 116.679,\n",
    "    41325: 40.596,\n",
    "    41367: 23.02,\n",
    "    41401: 190.075,\n",
    "    41415: 5.984,\n",
    "    41324: 37.274,\n",
    "    41332: 42.389,\n",
    "    41335: 52.452,\n",
    "    41330: 67.629,\n",
    "    41380: 5.642,\n",
    "    41327: 81.284,\n",
    "    41345: 80.167,\n",
    "    41342: 121.414,\n",
    "    41326: 280.698,\n",
    "    41361: 32.270\n",
    "}\n",
    "\n",
    "\n",
    "state_population = {\n",
    "    41336: 33.48283,\n",
    "    41325: 19.47651,\n",
    "    41367: 15.39601,\n",
    "    41401: 16.74621,\n",
    "    41415: 0.86908,\n",
    "    41324: 8.21110,\n",
    "    41332: 10.21064,\n",
    "    41335: 15.00817,\n",
    "    41330: 23.52743,\n",
    "    41380: 2.31541,\n",
    "    41327: 15.61383,\n",
    "    41345: 32.06742,\n",
    "    41342: 24.71140,\n",
    "    41326: 54.62141,\n",
    "    41361: 10.35977\n",
    "}\n",
    "\n",
    "state_area ={\n",
    "    41336:19102,\n",
    "41325:9500,\n",
    "41367:15099,\n",
    "41401:243,\n",
    "41415:91,\n",
    "41324:1664,\n",
    "41332:6686,\n",
    "41335:36137,\n",
    "41330:21035,\n",
    "41380:821,\n",
    "41327:1048,\n",
    "41345:73631,\n",
    "41342:124450,\n",
    "41326:8104,\n",
    "41361:13035}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP\n",
    "X_train_non_null['State_GDP'] = X_train_non_null.State.map(state_gdp)\n",
    "X_test_non_null['State_GDP'] = X_test_non_null.State.map(state_gdp)\n",
    "# Population\n",
    "X_train_non_null['State_Pop'] = X_train_non_null.State.map(state_population)\n",
    "X_test_non_null['State_Pop'] = X_test_non_null.State.map(state_population)\n",
    "# Area\n",
    "X_train_non_null['State_Area'] = X_train_non_null.State.map(state_area)\n",
    "X_test_non_null['State_Area'] = X_test_non_null.State.map(state_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_null.to_csv(\"X_train.csv\",index = False)\n",
    "X_test_non_null.to_csv(\"X_est.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_est.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'eta': 0.0123,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.85,\n",
    "    'tree_method': 'hist',\n",
    "    #'device': 'gpu',\n",
    "    'silent': 1,\n",
    "    'n_jobs':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:38] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.3123\tvalid-rmse:2.31258\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.704097\tvalid-rmse:1.01397\n",
      "[2000]\ttrain-rmse:0.514306\tvalid-rmse:1.0102\n",
      "[3000]\ttrain-rmse:0.37486\tvalid-rmse:1.00865\n",
      "Stopping. Best iteration:\n",
      "[2989]\ttrain-rmse:0.37625\tvalid-rmse:1.00852\n",
      "\n",
      "[23:41:47] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31227\tvalid-rmse:2.31278\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.709556\tvalid-rmse:1.04084\n",
      "[2000]\ttrain-rmse:0.516264\tvalid-rmse:1.03622\n",
      "[3000]\ttrain-rmse:0.375386\tvalid-rmse:1.03501\n",
      "Stopping. Best iteration:\n",
      "[2763]\ttrain-rmse:0.405023\tvalid-rmse:1.0344\n",
      "\n",
      "[23:47:18] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31216\tvalid-rmse:2.31248\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.705515\tvalid-rmse:1.01778\n",
      "Stopping. Best iteration:\n",
      "[1487]\ttrain-rmse:0.602255\tvalid-rmse:1.01477\n",
      "\n",
      "[23:50:44] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31233\tvalid-rmse:2.31268\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.709495\tvalid-rmse:1.00231\n",
      "[2000]\ttrain-rmse:0.515287\tvalid-rmse:0.997509\n",
      "Stopping. Best iteration:\n",
      "[2049]\ttrain-rmse:0.507195\tvalid-rmse:0.997018\n",
      "\n",
      "[23:55:27] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31225\tvalid-rmse:2.3128\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.706449\tvalid-rmse:1.0281\n",
      "[2000]\ttrain-rmse:0.514172\tvalid-rmse:1.02452\n",
      "Stopping. Best iteration:\n",
      "[1983]\ttrain-rmse:0.516965\tvalid-rmse:1.02429\n",
      "\n",
      "[23:59:36] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31232\tvalid-rmse:2.31274\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.706646\tvalid-rmse:1.01671\n",
      "[2000]\ttrain-rmse:0.509963\tvalid-rmse:1.00964\n",
      "Stopping. Best iteration:\n",
      "[2204]\ttrain-rmse:0.47779\tvalid-rmse:1.00883\n",
      "\n",
      "[00:04:16] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31218\tvalid-rmse:2.31291\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.702963\tvalid-rmse:1.0616\n",
      "[2000]\ttrain-rmse:0.510298\tvalid-rmse:1.05955\n",
      "[3000]\ttrain-rmse:0.371581\tvalid-rmse:1.05968\n",
      "Stopping. Best iteration:\n",
      "[2604]\ttrain-rmse:0.421516\tvalid-rmse:1.05866\n",
      "\n",
      "[00:09:37] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31232\tvalid-rmse:2.31239\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.707084\tvalid-rmse:1.02603\n",
      "[2000]\ttrain-rmse:0.514799\tvalid-rmse:1.02209\n",
      "[3000]\ttrain-rmse:0.375439\tvalid-rmse:1.02153\n",
      "Stopping. Best iteration:\n",
      "[2656]\ttrain-rmse:0.41819\tvalid-rmse:1.02046\n",
      "\n",
      "[00:15:03] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31233\tvalid-rmse:2.31215\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.705325\tvalid-rmse:1.01973\n",
      "[2000]\ttrain-rmse:0.514091\tvalid-rmse:1.01641\n",
      "[3000]\ttrain-rmse:0.375015\tvalid-rmse:1.01487\n",
      "Stopping. Best iteration:\n",
      "[2711]\ttrain-rmse:0.41039\tvalid-rmse:1.01431\n",
      "\n",
      "[00:20:43] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\ttrain-rmse:2.31249\tvalid-rmse:2.3123\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 500 rounds.\n",
      "[1000]\ttrain-rmse:0.70689\tvalid-rmse:1.02096\n",
      "[2000]\ttrain-rmse:0.515752\tvalid-rmse:1.01984\n",
      "Stopping. Best iteration:\n",
      "[1689]\ttrain-rmse:0.569727\tvalid-rmse:1.0189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def run_xgb(params, X_train, X_test):\n",
    "n_splits = 10\n",
    "verbose_eval = 1000\n",
    "num_rounds = 60000\n",
    "early_stop = 500\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n",
    "\n",
    "oof_train = np.zeros((X_train.shape[0]))\n",
    "oof_test = np.zeros((X_test.shape[0], n_splits))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n",
    "\n",
    "    X_tr = X_train.iloc[train_idx, :]\n",
    "    X_val = X_train.iloc[valid_idx, :]\n",
    "\n",
    "    y_tr = X_tr['AdoptionSpeed'].values\n",
    "    X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "    y_val = X_val['AdoptionSpeed'].values\n",
    "    X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n",
    "\n",
    "    d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n",
    "    d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n",
    "\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n",
    "                        early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n",
    "\n",
    "    valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n",
    "    test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    oof_train[valid_idx] = valid_pred\n",
    "    oof_test[:, i] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK =  0.4815330945625379\n"
     ]
    }
   ],
   "source": [
    "optR = OptimizedRounder()\n",
    "optR.fit(oof_train, X_train['AdoptionSpeed'].values)\n",
    "coefficients = optR.coefficients()\n",
    "valid_pred = optR.predict(oof_train, coefficients)\n",
    "# qwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, valid_pred)\n",
    "qwk = cohen_kappa_score(X_train['AdoptionSpeed'].values, valid_pred, weights=\"quadratic\")\n",
    "print(\"QWK = \", qwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pred distribution: Counter({2: 4329, 3: 3755, 4: 3683, 1: 2936, 0: 290})\n",
      "test pred distribution: Counter({0: 3948})\n"
     ]
    }
   ],
   "source": [
    "coefficients_ = coefficients.copy()\n",
    "train_predictions = optR.predict(oof_train, coefficients_).astype(np.int8)\n",
    "print(f'train pred distribution: {Counter(train_predictions)}')\n",
    "test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)\n",
    "print(f'test pred distribution: {Counter(test_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378fcc4fc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c10e136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72000c4c5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e147a4b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43fbba852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  378fcc4fc              0\n",
       "1  73c10e136              0\n",
       "2  72000c4c5              0\n",
       "3  e147a4b9f              0\n",
       "4  43fbba852              0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
